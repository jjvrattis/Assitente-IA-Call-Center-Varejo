import streamlit as st
from langchain_community.document_loaders import CSVLoader
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import PromptTemplate
import os

# ğŸ¯ Carregar API Key de forma segura
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]

# ğŸŒ¿ Estilo personalizado
st.set_page_config(page_title="Assistente Caedu ", layout="centered")
st.markdown("""
<style>
    body { background-color: #e7f5ec; }
    .stTextArea > div > textarea {
        background-color: #f0fff0;
        border: 1px solid #90ee90;
        border-radius: 6px;
    }
    .stButton > button {
        background-color: #2e8b57;
        color: white;
        border-radius: 8px;
        padding: 0.5em 1em;
    }
    .green-container {
        background-color: #d1f2d1;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #228B22;
        font-size: 1.1em;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# ğŸ§  Sidebar com histÃ³rico
with st.sidebar:
    st.title("ğŸ“š HistÃ³rico de DÃºvidas")
    
    # BotÃ£o para limpar
    if st.button("ğŸ§¹ Limpar histÃ³rico"):
        st.session_state["historico"] = []

    # Mostrar histÃ³rico, se existir
    for i, item in enumerate(st.session_state.get("historico", []), 1):
        st.markdown(f"**{i}.** {item}")

st.title("TÃ¡ com duvida? Pergunte ao Cadu ğŸ˜‰")

# ğŸ“¤ Upload de CSV customizado
#uploaded_file = st.file_uploader("ğŸ“„ Envie qualquer Arquivo CSV", type="csv")
#if uploaded_file:
    #file_path = "uploaded_base.csv"
    #with open(file_path, "wb") as f:
        #if.write(uploaded_file.getbuffer())
#else:
file_path = os.path.join(os.path.dirname(__file__), "Base_caedu.csv")

# ğŸ“¦ Carregar documentos
try:
    loader = CSVLoader(file_path=file_path, encoding="latin1")
    documents = loader.load()
    #st.success("âœ… Base de dados carregada.")
except Exception as e:
    st.error(f"âŒ Erro ao carregar CSV: {e}")
    st.stop()

# ğŸ” FunÃ§Ã£o de busca simplificada em memÃ³ria
def retrive_info(query):
    return [
        doc.page_content
        for doc in documents
        if query.lower() in doc.page_content.lower()
    ]

# âœï¸ Template de Prompt
template = """
VVocÃª Ã© uma assistente virtual para operadores de call center da Caedu. Seu papel Ã© responder dÃºvidas sobre cobranÃ§a, usando trechos extraÃ­dos de uma base de dados real.

âš ï¸ Regras:
1. Responda apenas sobre Caedu, mesmo que a dÃºvida seja externa.
2. Use obrigatoriamente os trechos abaixo como referÃªncia.
3. Ajude com foco em jovens de 16 a 23 anos, com linguagem clara e acessÃ­vel.
4. Seu nome Ã© Cadu.

ğŸ—¨ï¸ Mensagem recebida:
{message}

ğŸ“š Trechos extraÃ­dos da base:
{best_practice}

âœï¸ Escreva uma resposta que o operador possa repetir ao cliente, mantendo clareza e cordialidade:
"""
prompt = PromptTemplate(input_variables=["message", "best_practice"], template=template)
llm = ChatOpenAI(temperature=0.5, model="gpt-3.5-turbo", openai_api_key=OPENAI_API_KEY)
chain = prompt | llm

# ğŸ§ª Interface
# ğŸ§ª Interface
user_input = st.text_area("Digite a dÃºvida recebida pelo operador:")
if st.button("ğŸ’¡ Gerar resposta"):
    with st.spinner("Pensando na melhor resposta..."):
        best_practice = retrive_info(user_input)
        resposta = chain.invoke({
            "message": user_input,
            "best_practice": "\n".join(best_practice)
        })

    # âœ… Salvar dÃºvida no histÃ³rico da sessÃ£o
    if "historico" not in st.session_state:
        st.session_state["historico"] = []
    st.session_state["historico"].append(user_input)

    # ğŸ§  Mostrar resposta
    st.markdown("### ğŸ§  Resposta sugerida:")
    st.markdown(f"<div class='white-container'>{resposta.content}</div>", unsafe_allow_html=True)

    with st.expander("ğŸ“š Trechos usados como base"):
        for i, trecho in enumerate(best_practice, 1):
            st.markdown(f"**{i}.** {trecho}")

    with st.expander("ğŸ“š Trechos usados como base"):
        for i, trecho in enumerate(best_practice, 1):
            st.markdown(f"**{i}.** {trecho}")
